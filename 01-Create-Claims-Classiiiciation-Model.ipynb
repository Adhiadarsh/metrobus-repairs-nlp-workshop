{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ecbb0990-1473-4632-9e80-d1d8ff508881",
   "metadata": {},
   "source": [
    "In this notebook we are going to create labels for our test data, convert the labels to numbered indexes and then use one-hot encoding.  \n",
    "\n",
    "One hot encoding allows the representation of categorical data to be more expressive. Many machine learning algorithms cannot work with categorical data directly. The categories must be converted into numbers. This is required for both input and output variables that are categorical.\n",
    "\n",
    "After we have converted the labels using one-hot encoding, we are ready to build our main NLP model and train it.\n",
    "\n",
    "Once the model is trained, we can test our model by entering a claim (e.g. the brakes feel soft when I press on them) and check if the model has correctly characterized the claim.  \n",
    "\n",
    "Remember claims can be characterized as:  Other, Brakes or Starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98b5ca0f-aa59-4ecc-b79a-88d394d90881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca89ff56-3d68-48dd-ac82-93ad51f7cd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Have to cycle the ignition button at least twice before my car starts.  \\\n",
      "0       I tried starting my car but it doesn't work.                       \n",
      "1              I can't put gas in my steering wheel.                       \n",
      "2  My car makes a sputtering noise and does not t...                       \n",
      "3  Exhaust has a lot of black smoke and acrid smell.                       \n",
      "4           There is a lag when I open my rear trunk                       \n",
      "\n",
      "   starter  \n",
      "0  starter  \n",
      "1    other  \n",
      "2  starter  \n",
      "3    other  \n",
      "4    other  \n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_portion = .80  # Use 80% of data for training, 20% for testing\n",
    "max_words = 1000        #Max words in text input\n",
    "\n",
    "data = pd.read_csv('testdata1.csv')\n",
    "\n",
    "#print out first 5 rows of generated claims so you can see what data looks like\n",
    "print(data.head())\n",
    "\n",
    "train_size = int(len(data) * training_portion)\n",
    "\n",
    "def train_test_split(data, train_size):\n",
    "    train = data[:train_size]\n",
    "    test = data[train_size:]\n",
    "    return train, test\n",
    "\n",
    "train_cat, test_cat = train_test_split(data.iloc[:,1], train_size)  # label data is second column\n",
    "train_text, test_text = train_test_split(data.iloc[:,0], train_size)  # text data is first column\n",
    "\n",
    "tokenize = Tokenizer(num_words=max_words, char_level=False)\n",
    "tokenize.fit_on_texts(train_text) # fit tokenizer to our training text data\n",
    "\n",
    "#x_train and x_test are the vectorization of the text data (which is a claim)\n",
    "x_train = tokenize.texts_to_matrix(train_text)\n",
    "\n",
    "#following print statement shows some rows in the newly created matrix\n",
    "print(x_train)\n",
    "x_test = tokenize.texts_to_matrix(test_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1751d740-cc58-4d1a-8251-dcf5cc3ebc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 2 1 1 0 0 0 1 1 0 1 0 2 1 2 1 1 0 2 1 2 0 1 1 1 1 0 2 1 0 2 2 1 0 2 1\n",
      " 1 1 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 0 1 2 1 2 1 0 0 1 1 1 1 1 1 2\n",
      " 0 1 0 1 1 2 1 0 0 0 0 1 2 1 1 1 1 2 2 1 2 0 1 0 2 1 2 1 1 2 1 1 1 2 0 1 1\n",
      " 1 0 0 1 0 1 1 2 0 0 1 2 0 1 1 0 1 1 1 2 0 0 0 2 2 0 0 2 2 1 1 0 0 2 1 0 0\n",
      " 0 1 2 2 0 2 0 1 2 2 2 2 1 1 0 1 1 2 0 1 2 0 1 2 1 1 0 0 1 1 1 2 1 1 0 1 0\n",
      " 2 2 0 2 1 2 1 2 0 1 1 0 0 1 1 2 1 1 0 0 1 2 2 1 1 1 2 0 2 2 1 1 2 1 0 1 2\n",
      " 1 0 2 1 1 0 1 1 1 2 1 0 1 1 1 2 2 2 1 1 1 1 1 2 0 0 2 0 1 2 2 2 1 1 2 2 1\n",
      " 1 1 2 2 1 2 2 1 1 1 1 1 2 2 1 1 1 0 0 1 1 0 1 0 1 1 0 2 1 2 2 1 1 2 2 1 1\n",
      " 0 1 1 2 1 1 2 2 0 0 0 2 0 1 1 1 1 2 1 1 1 0 1 0 0 2 1 2 2 2 0 2 0 1 0 0 1\n",
      " 1 1 0 2 0 0 1 2 1 2 1 1 1 2 1 1 0 1 1 0 0 2 2 1 1 1 2 1 0 1 2 0 1 0 1 1 2\n",
      " 2 1 1 1 0 1 0 1 1 1 0 0 0 1 1 0 1 1 1 2 1 2 2 1 0 1 1 1 1 1 2 1 1 0 2 1 1\n",
      " 1 1 1 1 0 1 2 0 0 1 2 1 1 1 1 1 1 1 2 0 0 2 2 0 0 1 2 0 1 1 0 2 2 1 0 2 1\n",
      " 2 1 0 1 0 1 1 0 2 0 1 2 2 1 0 1 1 0 1 2 1 0 0 1 2 1 2 0 2 1 1 1 1 2 1 0 1\n",
      " 1 1 1 1 1 1 1 0 1 2 1 2 0 0 2 0 2 2 2 0 1 1 1 0 0 1 2 1 1 1 0 1 1 1 1 1 1\n",
      " 2 2 1 1 2 2 1 1 1 0 2 2 1 1 1 1 0 0 0 2 2 1 2 1 0 1 1 1 1 2 1 1 2 2 0 0 1\n",
      " 0 0 1 1 2 2 1 2 1 1 1 0 1 1 1 1 2 2 1 0 1 1 0 1 1 1 2 1 0 1 2 1 1 2 2 1 1\n",
      " 1 1 2 2 1 1 0 1 1 2 2 1 1 2 1 1 1 0 1 1 2 1 2 0 1 0 1 2 2 1 2 2 1 1 1 1 1\n",
      " 2 1 1 2 2 1 0 1 1 1 1 0 1 0 2 1 2 2 2 0 2 1 0 0 1 1 2 1 0 0 1 1 0 1 1 0 2\n",
      " 0 1 2 1 0 2 0 1 2 0 0 1 0 1 1 1 1 2 0 1 0 2 2 1 1 1 2 0 1 1 0 0 1 2 1 1 2\n",
      " 1 1 2 2 1 1 2 1 1 0 1 1 1 1 2 0 1 0 0 2 2 0 2 1 2 1 1 1 1 1 1 0 1 1 1 2 2\n",
      " 2 0 0 1 0 1 2 2 0 0 2 1 1 2 0 1 0 1 0 1 2 0 1 1 1 1 1 1 1 2 0 2 2 1 2 1 0\n",
      " 1 1 1 1 1 1 0 1 2 1 1 0 1 1 2 1 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn utility to convert label strings to numbered index\n",
    "encoder = LabelEncoder()  \n",
    "encoder.fit(train_cat)\n",
    "\n",
    "#convert label strings to numbers\n",
    "y_train = encoder.transform(train_cat)\n",
    "y_test = encoder.transform(test_cat)\n",
    "\n",
    "#for each row in the data, each entry represents the value of the label\n",
    "print(y_train)\n",
    "\n",
    "# for example:  [2 1 1 2 1 1 0 ...  which corresponds to starter, other, other, starter, other, other, brakes ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26517820-122d-41e3-97f1-ef3b4a09289e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (799, 1000)\n",
      "x_test shape: (200, 1000)\n",
      "y_train shape: (799, 3)\n",
      "y_test shape: (200, 3)\n"
     ]
    }
   ],
   "source": [
    "# Converts the labels to a one-hot representation\n",
    "\n",
    "num_classes = len(set(y_train))  # set() creates a unique set of objects\n",
    "#num_classes = np.max(y_train) + 1\n",
    "y_train = to_categorical(y_train, num_classes)  #one hot encoding replaces the column of labels whose (values are 0 or 1 or 2)\n",
    "# with 3 columns each representing 1 label value.  For example, the label 'other' is replaced by the vector 0 1 0, the label 'starter'\n",
    "#is replaced by the vector 0 0 1, the label 'brakes' is replaced by the vector 1 0 0\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Inspect the dimenstions of our training and test data\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "#one hot encoding\n",
    "#y_train shape: (159, 3)  159 rows, 3 columns\n",
    "#y_test shape: (40, 3)  40 rows, 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc05d7a6-7e54-4208-b743-0ffbb866dec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.9611 - accuracy: 0.5519 - val_loss: 0.5285 - val_accuracy: 0.9875\n",
      "Epoch 2/2\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.9708 - val_loss: 0.2110 - val_accuracy: 0.9875\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.9550\n",
      "Test loss: 0.2463839203119278\n",
      "Test accuracy: 0.9549999833106995\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "layers = keras.layers\n",
    "models = keras.models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, input_shape=(max_words,), activation='relu'))  # Hidden layer with 512 nodes\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#relu, softmax, categorical_crossentropy are telling the model how to do some internal calculations\n",
    "#softmax is telling the model to calculate probabilities for each category in each document.  If you only had yes, or no you would use sigmoid instead of\n",
    "#softmax.\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "history = model.fit(x_train, y_train,       # The variable, history, is normally used to plot learning curves.  fit calculates the weights in the model\n",
    "                    batch_size=batch_size,  # batch_size tells the internal calculations how many rows to process at one time\n",
    "                    epochs=epochs,          # epochs is the number of times the model calculations will pass through the entire data\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "score = model.evaluate(x_test, y_test,       #evaluate compares the model predictions with the actual known test values\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa5e0c35-d87e-4a10-8623-df1336deaf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returned prediction: {'predication': 'starter'}\n"
     ]
    }
   ],
   "source": [
    "# Here's how to generate a prediction on individual examples\n",
    "text_labels = encoder.classes_   #ndarray of output values (labels or classes)  e.g. other, brakes, starter\n",
    "\n",
    "# Examine first 10 test samples of 445\n",
    "for i in range(len(test_cat)):\n",
    "    temp = x_test[i]\n",
    "    prediction = model.predict(np.array([x_test[i]]))\n",
    "    predicted_label = text_labels[np.argmax(prediction)]  #predicted class\n",
    "    #print(test_text.iloc[i][:50], \"...\")                # 50 char sample of text\n",
    "    #print('Actual label:' + test_cat.iloc[i])\n",
    "    #print(\"Predicted label: \" + predicted_label + \"\\n\")\n",
    "\n",
    "#test our model by inputing a new user claim =============   \n",
    "#print('================================  ENTER TEST PHRASE ====================================')\n",
    "#single_test_text = 'press brake pedal and car wont stop'  #text has to be a document, the brackets make it a document\n",
    "single_test_text = 'turn key over and hear a clicking sound' \n",
    "#single_test_text = 'there is fluid leaking from the engine' \n",
    "\n",
    "#print(\"Entered text: \" + str(single_test_text) + \"\\n\")\n",
    "\n",
    "#text_as_nparray = np.array([single_test_text])\n",
    "text_as_series = pd.Series(single_test_text)  #data conversions\n",
    "\n",
    "single_x_test = tokenize.texts_to_matrix(text_as_series)\n",
    "single_prediction = model.predict(np.array([single_x_test]))\n",
    "single_predicted_label = text_labels[np.argmax(single_prediction)]  #maps index of the prediction to the test labels array e.g. brakes\n",
    "#print(\"Predicted label: \" + single_predicted_label + \"\\n\")\n",
    "\n",
    "#======================================\n",
    "#test predication function\n",
    "#======================================\n",
    "#print('=====================test prediction function==================================')\n",
    "\n",
    "def predict(single_test_text):\n",
    "    text_as_series = pd.Series(single_test_text) #do a data conversion\n",
    "    single_x_test = tokenize.texts_to_matrix(text_as_series)\n",
    "    single_prediction = model.predict(np.array([single_x_test]))\n",
    "    single_predicted_label = text_labels[np.argmax(single_prediction)]  #maps index of the prediction to the test labels array e.g. brakes\n",
    "    #return {'prediction': license_plate_string}\n",
    "    return {'predication': single_predicted_label}\n",
    "\n",
    "prediction = predict(single_test_text)  #call the prediction function\n",
    "\n",
    "print('returned prediction: ' + str(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70e603b3-f4e2-428f-857b-8829d4ba270f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predication': 'other'}\n"
     ]
    }
   ],
   "source": [
    "prediction = predict('there is a pool of liquid under the car')\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
